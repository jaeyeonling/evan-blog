---
title: JavaScript로 오디오 이펙터를 만들어보자
toc: true
widgets:
  - type: toc
    position: right
  - type: category
    position: right
sidebar:
  right:
    sticky: true
tags:
  - JavaScript
  - Audio
  - 오디오 이펙터
  - JavaScript Audio API
categories:
  - JavaScript
thumbnail:
---

이번 포스팅에서는 {% post_link javascript-audio-waveform 컴퓨터는 어떻게 소리를 들을까? %} 포스팅에서 진행했던 오디오 파형 그리기에 이어서 오디오에 여러가지 효과를 줄 수 있는 이펙터를 만드는 과정을 설명하려고 한다. HTML5의 Audio API는 오디오에 효과를 줄 수 있는 여러가지 노드를 제공하는데, 대부분의 이펙터는 이 노드들만 사용해도 구현할 수 있을 정도로 완성도있는 API를 제공한다.
<!-- more -->

지난 포스팅에서 이미 소리에 관한 기본적인 이론을 설명했으니 이번에는 오디오에 여러가지 효과를 주기 위한 방법들을 조금 더 자세히 설명하겠다.

## 오디오 신호는 흐르는 것이다
일반적인 녹음실에서 우리는 마이크를 통해서 오디오를 수집하거나 혹은 이미 녹음된 오디오를 `DAW(Digital Audio Workstation)`으로 불러와서 사용하게 된다. 이때 처음으로 받게되는 이 오디오를 `소스(Source)`라고 한다.

이 소스는 앰프, 컴프레서, 이퀄라이저 등의 여러가지 이펙터들을 지나서 최종적으로 스피커나 헤드폰을 통해서 출력되게 된다. 이 흐름을 알고나면 HTML5의 Audio API가 제공하는 `노드(Node)`의 개념을 쉽게 이해할 수 있다. 일단 이해를 돕기 위해 필자가 예전에 사운드 엔지니어로 일할 때 사용했던 시스템을 예로 들겠다.

<center>
  {% asset_img mixer.jpg 500 %}
  <small>필자가 예전에 사용했던 장비들</small>
  <br>
</center>

사진의 중앙에 있는 커다란 장비는 아마 여러분도 TV에서 몇번 보았던 장비일 것이다. 이 장비는 여러 개의 채널로 나눠진 오디오 소스의 볼륨이나 패닝, 이퀄라이징까지 할 수 있는 일종의 컨트롤 타워 역할을 하는 믹싱 콘솔이다.

그리고 믹싱 콘솔의 오른쪽에 있는 것들이 바로 오디오에 효과를 줄 수 있는 이펙터들이다. 보통은 믹싱 콘솔 양쪽에 가득 채워놓고 쓰는데 저 사진은 아직 녹음실 셋업이 덜 끝났을 때라서 몇가지 장비만 들어가 있다. 그리고 사진에는 나오지 않았지만 따로 `콘솔 랙(Console Rack)`이라는 선반을 두고 거기에도 이펙터들이 가득 채워져 있다.

그리고 이펙터들의 위쪽을 보면 붉은색 선이 꽂혀있는 것을 볼 수 있는데, 저 장비가 `오디오의 흐름`을 컨트롤할 수 있는 `패치 테이블(Patch Table)`이라고 하는 장비이다.

보통 사운드 엔지니어들은 같은 역할을 하는 이펙터라고 하더라도 여러 종류의 장비를 사용하게 되는데, 이는 같은 역할을 하는 이펙터라고 하더라도 장비마다 조금씩 소리가 다를 수 있기 때문이다. 즉, 같은 리버브를 사용한다고 해도 최종적으로 만들고자하는 소리가 어떤 느낌인지에 따라 `A 리버브`를 사용할 수도 있고 `B 리버브`를 사용할 수도 있다는 것이다.

하지만 다른 이펙터를 사용하고 싶을 때마다 장비에 꽂혀있는 케이블을 일일히 하나하나 빼서 다시 다른 장비에 연결하는 것은 비효율적이기도 하고 케이블을 계속 뺐다가 꼈다가 하면 장비에 손상이 갈수도 있기 때문에 모든 장비의 라인을 저 패치 테이블에 연결해놓고 사용하는 것이다.<small>(게다가 케이블은 대부분 장비 뒤쪽에 위치하기 때문에 저 믹싱 콘솔을 앞으로 살짝 밀고 봐야한다)</small>

<center>
  {% asset_img patch_table_chart.jpeg 500 %}
  <small>대략 이런 느낌으로 정리된다</small>
  <br>
</center>

이 오디오의 흐름이라는 개념은 굉장히 중요하다. 필자가 방금 예로 든 하드웨어 장비 뿐만 아니라 소프트웨어로 구현된 이펙터를 사용하려할때도 결국은 이 흐름을 프로그램 내부에서 그대로 구현해줘야하기 때문이다.

<center>
  {% asset_img protools.png 300 %}
  <br>
</center>

위 사진은 전 세계 녹음실 중 90%가 사용하고 있는 Protools라는 DAW의 믹서 창이다. 사진에 강조된 부분에 `Vocal Bus`라고 적혀있는 곳을 보면 맨 오른쪽 채널은 위쪽에 위치하고 있고 나머지 채널은 아래쪽에 위치하고 있다. `I/O` 메뉴에서 위쪽은 `In`을 의미하고 아래쪽은 `Out`을 의미하기 때문에 이 그림에서 오디오의 흐름은 대략 다음과 같이 나타날 수 있다.

<center>
  {% asset_img auxes.png %}
</center>

이때 저 네모 하나하나가 HTML5의 Audio API에서 제공해주는 `노드`와 정확히 같은 개념이다.

이해를 돕기 위해 저 노드들의 역할에 대해서 조금 더 부가설명을 하자면, 일단 `Lead Vox`는 말 그래도 보컬의 노래 소스를 가진 노드이고 `LeadVxDbl`은 노래를 풍부하게 들리게 하기 위해 같은 멜로디를 한번 더 녹음한 것, 즉 더블링 작업을 한 노드이다. 그리고 `Vox Fill`은 화음을 쌓은 코러스를 담은 노드일 것 같다.

그리고 보컬이 노래한 이 오디오 소스를 모두 `Vocal Bus`라는 노드로 모으고 있다. 이렇게 하는 이유는 여러 개의 오디오 소스에 이펙터를 각각 사용하면 노드마다 조금씩 소리의 느낌이 달라질 수 있기 때문에 한 노드로 소스를 모아서 해당 노드에만 이펙터를 걸어주는 것이다.

그리고 `Sub Master` 노드는 아마 최종 아웃풋으로 소리가 나가기 전에 한번 더 이펙터 처리를 하고 싶어서 생성한 것일 테고, Sub Master까지 도달한 오디오는 아웃풋, 즉 스피커를 통해 나오게 되는 것이다.

이제 오디오 소스의 흐름이라는 것이 대략 이해가 되었으면 한번 직접 HTML5의 Audio API를 사용해서 이 흐름을 구현해보도록 하자.

## 노드를 사용하여 오디오의 음량을 조절하기
본격적으로 이펙터를 구현해보기에 앞서, 오디오의 흐름을 직접 만들어보도록 하자. HTML5 Audio API의 `GainNode`를 사용하면 오디오 소스의 음량을 손쉽게 조절할 수 있다.



## 이펙터를 구현해보자
### Compressor
### Reverb
### Delay
### Filter
### EQ

