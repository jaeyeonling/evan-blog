---
title: 패킷의 흐름을 제어하는 TCP
toc: true
widgets:
  - type: toc
    position: right
  - type: category
    position: right
sidebar:
  right:
    sticky: true
tags:
categories:
thumbnail:
---

`TCP(Transmission Control Protocol)`은 이름 그대로 전송을 제어하는 프로토콜로써, 전송을 제어하기 위한 흐름 제어와 혼잡 제어 등의 기능을 프로토콜 자체에 포함하고 있다.

<!-- more -->

이번 포스팅에서는 TCP 시리즈 중 `흐름 제어`, `혼잡 제어`, `오류 제어`에 대한 내용을 이야기해보려고 한다.

## TCP의 흐름 제어
송신 측과 수신 측이 서로 데이터를 주고 받을 때, 여러가지 요인에 따라 이 두 친구들의 처리 속도가 달라질 수 있다. 이때 데이터를 받는 수신 측의 처리 속도가 송신 측보다 빠른 경우는 사실 별 문제가 없다.

주는 족족 빠르게 처리해주니 딱히 문제될 것이 없는 것이다. 그러나 수신 측의 처리 속도보다 송신 측이 더 빠른 경우 문제가 생긴다.

송신 측과 수신 측은 모두 데이터를 저장할 수 있는 버퍼를 가지고 있다. 이때 수신 측이 자신의 버퍼 안에 있는 데이터를 처리하는 속도보다 송신 측이 데이터를 전송하는 속도가 더 빠르다면, 당연히 수신 측의 버퍼는 언젠가 꽉 차버릴 것이기 때문이다.

수신 측의 버퍼가 꽉 찬 상태에서 도착한 패킷은 더 이상 담아둘 공간이 없기 때문에 폐기 처분된다. 물론 이런 상황에서는 송신 측이 다시 패킷을 보내주기는 하겠지만, 패킷을 재전송하는 과정이 다시 동반되어야하기 때문에 사실 상 리소스 낭비라고 볼 수 있다.

그래서 송신 측은 수신 측의 데이터 처리 속도를 파악하고 자신이 얼마나 빠르게, 많은 데이터를 전송할 지 결정해야한다. 이것이 바로 TCP의 흐름 제어인 것이다.

수신 측은 자신이 처리할 수 있는 데이터의 양을 의미하는 `윈도우 크기(Window Size)`를 자신의 응답 헤더에 담아서 송신 측에게 전해주게 되고, 송신 측은 상대방에게 데이터를 보낼 때 이 윈도우 크기를 참고해서 알맞은 양의 데이터를 보냄으로써 전체적인 데이터의 흐름을 제어하게 된다.

### Stop and Wait
`Stop and Wait` 방식은 이름 그대로 상대방에게 데이터를 보낸 후 잘 받았다는 응답이 올 때까지 기다리는 모든 방식을 통칭하는 말이다. 이때 데이터를 받는 수신 측은 `잘 받았어!`와 `못 받았어...` 등의 대답을 해주게 되는데, 수신 측이 어떤 대답을 해주냐에 따라 사용할 수 있는 오류 제어 방법이 나눠지기도 한다.

<center>
  {% asset_img stop-and-wait.png 400 %}
  <br>
</center>

Stop and Wait로 흐름 제어를 할 경우의 대원칙은 단순히 `상대방이 응답을 하면 데이터를 보낸다`이기 때문에 구현 자체도 간단하고 프로그래머가 어플리케이션의 작동 원리를 파악하기도 쉬운 편이다.

기본적인 `ARQ(Automatic Repeat Request)`를 구현한다고 생각해보면, 수신 측의 윈도우 크기를 1 byte로 설정하고 `처리 가능 = 1`, `처리 불가능 = 0`과 같은 식으로 대충 구현해도 돌아가기는 하기 때문이다.

하지만 서로 `처리 가능`, `처리 불가능` 정도의 의미만 주고받는 방식은 간단한만큼 비효율적이라고 할 수도 있다.

즉, 송신 측은 수신 측이 어느 정도의 크기의 버퍼를 가지고 있는지, 처리 능력이 얼마나 되는지 전혀 모르는 상태이기 때문에 항상 전송을 시도해보고 나서야 수신 측이 이 데이터를 처리할 수 있을지 없을지 알 수 있기 때문이다.

그런 이유로 Stop and Wait 방식을 사용하여 흐름 제어를 할 경우에는, 이런 비효율성을 커버하기 위해 이런 단순한 구현이 아닌 여러가지 오류 제어 방식을 함께 도입해서 사용한다.

### Sliding Window
`슬라이딩 윈도우(Sliding Window)`는 수신 측이 한 번에 처리할 수 있는 데이터를 정해놓고 그때그때 수신 측의 데이터 처리 상황을 송신 측에 알려줘서 데이터의 흐름을 제어하는 방식이다.

Stop and Wait과 여러 가지 차이점이 있겠지만, 사실 가장 큰 차이점은 송신 측이 `수신 측이 처리할 수 있는 데이터의 양`을 알고 있다는 점이다. 이 정보를 알고 있기 때문에 굳이 수신 측이 `처리 가능`이라는 대답을 일일히 해주지 않아도 어느 정도 예측이 가능하다는 말이다.

송신 측과 수신 측은 각각 데이터를 담을 수 있는 버퍼를 가지고 있고, 별도로 `윈도우`라는 일종의 마스킹 도구를 가지고 있다. 이때 송신 측은 이 윈도우에 들어있는 데이터를 수신 측의 응답이 없어도 연속적으로 보낼 수 있다.

<center>
  {% asset_img window.png 500 %}
  <small>윈도우 안에 들어있는 프레임은 수신 측의 응답이 없이도 연속으로 보낼 수 있다</small>
  <br>
</center>

송신 측의 윈도우 크기는 맨 처음 TCP의 연결을 생성하는 과정인 3 Way Handshake 때 결정된다.

핸드쉐이크 과정에서 ACK 응답을 하는 수신 측이 송신 측에게 자신의 윈도우 크기를 헤더에 담아서 알려주면, 송신 측은 수신 측이 보내준 윈도우 크기와 자신이 SYN 패킷을 보냈을 때 상대방이 ACK 응답을 보냈던 시간 차를 사용하여 자신의 윈도우 크기를 결정한다.

즉, 송신 측의 윈도우 크기는 수신 측의 처리 속도와 네트워크 환경에 따라 유연하게 설정된다. 수신 측의 처리 속도가 빠를 수록 송신 측의 윈도우 크기도 커지고, 수신 측의 처리 속도가 느릴 수록 송신 측의 윈도우 크기도 줄어드는 것이다.

그리고 이때 정해진 윈도우 크기는 고정이 아니라 통신을 하는 과정 중간에도 계속 네트워크의 혼잡 환경과 수신 측이 보내주는 윈도우 크기를 통해 동적으로 변경될 수 있다. 윈도우의 크기, 즉 연속적으로 보낼 데이터의 양을 변경해가면서 유연하게 흐름 제어를 할 수 있다는 말이다.

윈도우에 대해 대략적으로 이해를 했다면 이제 이 기법을 왜 `슬라이딩 윈도우`라고 하는 지 한번 살펴보도록 하자.

먼저, 송신 측이 `0 ~ 6`번의 시퀀스 번호를 가진 데이터를 상대방에게 전송하고 싶어하는 상황을 상상해보자. 이때 송신 측의 버퍼에는 전송해야할 데이터들이 이렇게 담겨져 있을 것이다.

<center>
  {% asset_img sw-0.png 500 %}
  <br>
</center>

이때 송신 측은 수신 측에게 받은 윈도우 크기와 현재 네트워크 상황을 고려하여 윈도우 크기를 3으로 잡았고, 윈도우 안에 있는 데이터를 우선 주르륵 전송한다.

<center>
  {% asset_img sw-1.png 500 %}
  <br>
</center>

이때 윈도우 안에 들어있는 데이터는 어떤 상태일까? 일단 데이터를 전송하기는 했지만 아직 수신 측으로부터 잘 받았다는 응답을 받지 못한 상태일 것이다.

즉, 윈도우에 들어있는 데이터들은 항상 `전송은 했지만, 상대방이 처리했는지는 모르는 상태`라고 할 수 있다.

이후 수신 측은 자신의 처리 속도에 맞게 데이터를 처리한 후 응답으로 현재 자신의 버퍼에 남아있는 공간의 크기를 알려준다. 만약 수신 측이 응답으로 `Window Size: 1`을 보냈다면 "내 버퍼 공간이 1 byte만큼 남았으니까 그 만큼만 더 보내봐"라는 의미가 된다.

이제 송신 측은 자신이 데이터 한 개를 더 보낼 수 있다는 사실을 알았으니, 자신의 윈도우를 한 칸 옆으로 밀고 새롭게 윈도우에 들어온 3번 데이터를 수신 측에게 전송한다.

<center>
  {% asset_img sw-2.png 500 %}
  <br>
</center>

이때 윈도우를 옆으로 이동시키며 새로 들어온 데이터를 전송하기 때문에 `슬라이딩 윈도우`라고 하는 것이다. 만약 수신 측이 윈도우 크기를 1이 아니라 더 큰 수를 보냈다면, 송신 측은 그 만큼 윈도우를 옆으로 밀고 더 많은 데이터를 연속적으로 전송할 수 있을 것이다.

단, 이 경우 송신 측의 윈도우 크기가 3이기 때문에 수신 측이 4를 보냈다고 해서 4칸을 밀지는 않고, 자신의 윈도우 크기인 3만큼만 밀 수 있다.

이렇게 데이터를 전송하는 송신 측의 버퍼는 대략 3가지 상태로 나눠질 수 있다.

<center>
  {% asset_img sw-3.png 500 %}
  <br>
</center>

즉 슬라이딩 윈도우 방식은 `보내고 -> 응답받고 -> 윈도우 밀고`를 반복하면서, 현재 자신이 보낼 수 있는 데이터를 최대한 연속적으로 보내는 방법이라고 할 수 있다.

이게 지금 `0 ~ 6` 밖에 안되는 단순화된 그림으로 봐서 잘 와닿지 않을 수도 있지만, 아무런 옵션도 적용하지 않은 TCP의 최대 윈도우 크기는 `65,535 bytes`이고, 연속적으로 한번에 보내는 데이터도 이렇게 한 개, 두 개 정도가 아니라 몇 백 바이트 단위로 보내는 경우가 많다.

즉, 이론적으로는 수신 측의 ACK 응답 없이도 최대 65,535 bytes를 연속적으로 전송할 수 있다는 말이 된다.

Stop and Wait가 일일히 하나 보내고, 응답 받고 하는 것과 비교해보면 확실히 전송 속도 측면에서 빠르기도 하고, 송신 측과 수신 측의 지속적인 커뮤니케이션을 통해 윈도우 크기 또한 유연하게 조절할 수 있기 때문에 Stop and Wait 방식보다 구현은 조금 복잡해도 효율이 좋은 편이다.

## TCP의 오류 제어
TCP는 기본적으로 `ARQ(Automatic Repeat Request)`, 재전송 기반 오류 제어를 사용한다. 말 그대로 통신 중에 뭔가 오류가 발생하면 송신 측이 수신 측에게 해당 데이터를 다시 전송해야한다는 말이다.

이때 송신 측은 자신이 데이터를 보낸 후 타이머를 돌려서, 자신이 설정한 타임아웃 시간이 지나도 상대방으로부터 아무런 응답이 없다면 오류가 발생했다고 판단하고 해당 데이터를 재전송하면 되는 단순한 작업을 하지만 수신 측은 조금 더 많은 일을 한다.

수신 측은 자신이 데이터를 처리하다가 뭔가 오류가 발생하거나, 송신 측이 보낸 데이터를 뜯어서 체크섬을 확인했는데 뭔가 변조가 의심된다거나 하는 다양한 경우에 부딫히게 되기 때문이다. 이런 식으로 수신 측은 오류를 발견하면 송신 측에게 해당 데이터를 다시 요청하는 피드백을 보내줘야한다.

하지만 이 `재전송`이라는 작업 자체가 했던 일을 또 해야하는 비효율적인 작업이기 때문에, 이 재전송 과정을 최대한 줄일 수 있는 여러가지 방법을 사용하게 된다.

### Stop and Wait
`Stop and Wait`는 흐름 제어 때 한번 살펴보았던, 한번 데이터를 보내면 `제대로 받았다`라는 응답이 올 때까지 대기하고 있다가 다음 데이터를 보내는 방식이다.

이 친구가 오류 제어에서 다시 나오는 이유는 그냥 이렇게만 해도 기본적인 오류 제어가 가능하기 때문이다. 일석이조랄까. 애초에 제대로 받았다는 응답이 오지 않는다면 제대로 받을 때까지 계속 데이터를 재전송하는 방법이니까 흐름 제어도 되지만 오류 제어도 가능하다.

<center>
  {% asset_img stop-and-wait-error.png 400 %}
  <br>
</center>

그러나 위에서 살펴본 `슬라이딩 윈도우`를 사용할 때는 윈도우 안에 있는 데이터를 `연속적`으로 보내야 하기 때문에, 오류 제어에 Stop and Wait를 사용해버리면 슬라이딩 윈도우를 쓰는 이점을 잃어버린다.

그런 이유로 일반적으로는 이런 단순한 방법보다 조금 더 효율적이고 똑똑한 ARQ를 사용하게 된다.

### Go Back N
`Go Bank N` 방법은 데이터를 연속적으로 보내다가 그 중 `어느 데이터부터 오류가 발생했는지`를 검사하는 방식이다.

이때 수신 측은 잘 받았다는 응답인 `ACK` 외에도, 제대로 받지 못했다는 응답인 `NACK`를 사용하여, 송신 측에게 자신의 데이터 처리 상황을 알릴 수 있다.

Go Back N 방식을 사용하면 데이터를 연속적으로 보낸 후 한 개의 ACK 응답, NACK 응답만을 사용하여 수신 측의 처리 상황을 파악할 수 있으므로, 연속적으로 데이터를 보낼 수 있는 흐름 제어 방식인 슬라이딩 윈도우와 아주 잘 들어맞는다고 할 수 있다.

<center>
  {% asset_img go-back-n.png 400 %}
  <br>
</center>

위 그림을 보면 수신 측이 4번 데이터부터 에러가 발생함을 감지하고 송신 측에게 `4번부터 다시 보내줘`라고 하고 있다.

Go back N 방식에서 수신 측이 4번 데이터에서 에러가 발생했음을 감지하면, 4번 데이터 이후 자신이 받았던 모든 데이터를 폐기하고 송신 측에게 NACK를 보내게 된다.<small>(쏘쿨)</small>

즉, 송신 측은 수신 측으로 NACK를 받고나면 오류가 발생한 4번 데이터와 그 이후 전송했던 모든 데이터를 다시 전송해줘야 한다는 말이 된다. 이때 송신 측은 비록 5번까지 전송했지만 오류가 발생하면, 오류가 발생한 4번 데이터로 되돌아가서 다시 전송해야하므로 `Go Back N`이라고 부르는 것이다.

### Selective Repeat
`Selective Repeat`은 말 그대로 `선택적인 재전송`을 의미한다. Go Back N 방법도 Stop and Wait에 비하면 많이 효율적인 방법이지만, 에러가 발생하면 그 이후에 정상적으로 전송되었던 데이터까지 모두 폐기 처분되어 다시 전송해야한다는 비효율이 아직 존재한다.

그래서 나온 방식이 `에러난 데이터만 재전송해줘` 방식인 것이다.

<center>
  {% asset_img selective-repeat.png 400 %}
  <br>
</center>

얼핏 보면 이 방식이 굉장히 효율적이고 좋기만 한 것 같지만 Stop and Wait와 Go Back N 방식과 다르게, 이 방식을 사용하는 수신 측의 버퍼에 쌓인 데이터가 연속적이지 않다는 단점이 존재한다.

위 예시만 봐도 수신 측의 버퍼에는 `0, 1, 2, 3, 4, 5`가 순차적으로 들어있는 것이 아니라, 중간에 폐기 처분된 4를 제외한 `0, 1, 2, 3, 5`만 버퍼에 존재할 것이기 때문이다. 이때 송신 측이 4를 재전송하게되면 수신 측은 이 데이터를 버퍼 중간 어딘가에 끼워넣어서 데이터를 정렬해야한다.

이때 같은 버퍼 안에서 데이터를 정렬할 수는 없으니, 별도의 버퍼가 필요하게 된다.

결국 재전송이라는 과정이 빠진 대신 재정렬이라는 과정이 추가된 것인데, 이 둘 중에 재전송이 좀 더 이득이라고 생각되면 Go Bank N 방식을, 재정렬이 좀 더 이득이라고 생각되면 Selective Repeat 방식을 사용하면된다.

만약 TCP 통신에서 Selective Repeat 방식을 사용하고 싶다면, TCP의 옵션 중 `SACK` 옵션을 1로 설정하면 된다...만 사실 기본적으로 켜져 있는 경우가 많다.

```bash
$ sysctl net.inet.tcp | grep sack
net.inet.tcp.sack: 1
net.inet.tcp.sack_maxholes: 128
net.inet.tcp.sack_globalmaxholes: 65536
net.inet.tcp.sack_globalholes: 0
```

OSX 같은 경우, `sysctl` 명령어를 사용하여 TCP와 관련된 커널 변수들을 확인해보면 그 중 `net.inet.tcp.sack` 값이 1로 잡혀있는 것을 확인할 수 있다.

## TCP의 혼잡 제어
혼잡 제어란, 말 그대로 네트워크의 혼잡 상태를 파악하고 그 상태를 해결하기 위해 데이터 전송을 제어하는 것을 이야기한다.

네트워크는 워낙 광대한 블랙박스이기 때문에 정확히 어디서 어떤 이유로 전송이 느려지는지는 파악하기 힘들지만, 단순히 `느려지고있다` 정도는 각 종단에서도 충분히 파악할 수 있다. 그냥 데이터를 보냈는데 상대방으로부터 응답이 늦게 오거나 안오면 뭔가 문제가 있다는 것이니 말이다.

이때 위에서 이야기한 흐름 제어나 오류 제어 기법들만을 사용하다보면 자연스럽게 `재전송`이라는 작업이 계속 반복될 수 밖에 없다.

이게 한 두 녀석이 그러면 별 문제가 안될지도 모르지만, 네트워크는 워낙 다양한 친구들이 함께 이용하는 공간이다보니까 한번 네트워크가 뻑나기 시작하면 여기저기서 `나도 재전송할꺼야!`가 반복되면서 문제가 점점 악화될 것이다.

이런 식으로 네트워크의 혼잡 상태가 감지되면, 이런 최악의 상황을 최대한 회피하기 위해 송신 측에서 보내는 데이터의 전송 속도를 강제적으로 줄이게 되는데, 이것이 바로 `혼잡 제어`인 것이다.

### AIMD
`AIMD(Addtive Increase / Multicative Decrease)` 방식은 우리 말로 직역하면 합 증가 / 곱 감소 방식이라는 뜻이다. 즉, 네트워크에 아직 별 문제가 없어서 전송 속도를 더 빠르게 하고 싶다면 윈도우 크기를 1씩 증가시키지만, 중간에 데이터가 유실되거나 응답이 오지 않는 등의 혼잡 상태가 감지되면 윈도우 크기를 반으로 줄인다.

늘어날 때는 `ws + 1`, 줄어들 때는 `ws * 0.5`이므로 말 그대로 합 증가 / 곱 감소 인 것이다. 이렇게 윈도우 크기를 한번 조절하고 나면 다시 선형적으로 윈도우 크기를 증가시키다가 또 문제가 발생하면 또 윈도우 크기를 반으로 확 줄여버린다.

이렇게 늘어날 때는 조금씩 늘어나고 줄어들 때는 확 줄어드는 AIMD 방식의 특성 상, 이 방식을 사용하는 연결의 윈도우 크기는 대략 다음과 같은 톱니 모양이 나타난다.

<center>
  {% asset_img aimd.png 500 %}
  <br>
</center>

이 방식은 굉장히 심플하지만 생각보다 공평한 방식이다. 예를 들어 여러 친구들이 이미 네트워크를 점유하고 있는 상태에서 한 친구가 뒤늦게 이 네트워크에 합류했다고 생각해보자.

당연히 나중에 진입하는 쪽이 처음에는 불리하겠지만, 어차피 나중에 네트워크가 혼잡해지면 나중에 들어온 놈보다 먼저 들어와있는 놈의 윈도우 크기가 더 클 확률이 높기 때문에 임계점에 걸려서 `곱 감소` 당할 가능성도 더 높다.

나중에 들어온 친구는 조금씩 윈도우 크기를 증가시켜나갈테고, 먼저 들어와 있는 친구는 곱 감소로 인해 윈도우 크기가 확 줄어들기 때문에, 시간이 가면 갈수록 호스트들의 윈도우 크기가 평행 상태로 수렴하게 되는 것이다.

그러나 AIMD의 문제점은 네트워크 대역이 펑펑 남아도는 상황에도 윈도우 크기를 너무 조금씩 늘리면서 접근한다는 것이다. 그런 이유로 AIMD 방식은 네트워크의 모든 대역을 활용하여 제대로 된 속도로 통신하기까지 시간이 조금 걸린다.

또한 네트워크가 혼잡해지고 나서야 `어, 윈도우 크기 줄여야겠다`하는 소 잃고 외양간 고치는 방식이기 때문에 네트워크의 혼잡 상황을 미리 예측하지 못한다는 단점도 있다.

#### AIMD를 간단히 구현해보자!
사실 AIMD는 워낙 단순한 방식이다 보니 간단한 예제를 통해 네트워크의 상황을 재현해볼 수도 있다. 이렇게 직접 구현해보면 말로만 들었을 때는 애매한 `호스트들의 윈도우 크기가 평행으로 수렴한다는 것`이 어떤 의미인지 직접 눈으로 확인해볼 수도 있다.

```js
class Host {
  constructor (i) {
    this.name = `host${i}`;
    this.windowSize = 1;
    this.threshold = 10;
  }

  aimd (isFullCongestion) {
    return new Promise((resolve) => {
      if (isFullCongestion && this.windowSize > this.threshold) {
        this.windowSize *= 0.5;
      }
      else {
        this.windowSize++;
      }
      resolve();
    });
  }
}
```

뭐 대충 이런 친구가 있다고 생각해보자. 필자는 이 클래스를 사용하여 `100ms` Host 객체를 하나씩 생성하여 최대 10개까지 네트워크에 집어넣을 것이다.

Host 클래스의 `aimd` 메소드는 외부로부터 현재 네트워크의 혼잡도가 한계치인지를 받아와서 확인한 후, 현재 자신의 윈도우 크기가 자신이 정한 임계점보다 높다면 곱 감소를, 낮다면 합 증가를 할 것이다.

```js
class Network {
  constructor () {
    this.hosts = [];
    this.congestion = 0;
    this.MAX_CONGESTION = 50;
  }

  addHost (host) {
    this.hosts.push(host);
  }

  calcCongestion () {
    this.congestion = this.hosts.reduce((prev, current) => {
      return prev + current.windowSize;
    }, 0);
  }

  start () {
    let count = 0;
    const interval = setInterval(() => {
      count++;

      this.calcCongestion();
      Promise.all(this.hosts.map(host => {
        return host.aimd(this.congestion > this.MAX_CONGESTION);
      })).then(() => {
        // 여기는 그냥 결과 출력을 위한 부분이다
        let s = '';
        this.hosts.forEach(host => {
          s += `${host.name}: ${host.windowSize}\n`
        });
        console.log(`Phase ${count} ==============`);
        console.log(s);
      });

      if (count > 200) {
        clearInterval(interval);
      }
    }, 10);
  }
}
```

Network 클래스의 `addHost`와 `calcCongestion` 메소드는 가독성을 위해 따로 분리해놓은 작업들이니 주의 깊게 볼 필요는 없다.

이 클래스에서 메인 작업을 맡는 부분은 바로 `start` 메소드인데, 이 메소드는 10ms마다 호스트들의 윈도우 크기를 가져와서 현재 네트워크의 혼잡도를 계산하고, 호스트 객체들의 `aimd` 메소드를 실행시키는 역할을 한다.

이때 for 루프를 돌리면 항상 `hosts` 배열의 앞쪽에 있는 친구들만 곱 감소를 당할것이기 때문에 `Promise.all`을 사용하여 최대한 동시성을 보장하였다.<small>(사실 이것도 완벽한 동시는 아니다...)</small>

사실 굳이 비동기 프로그래밍을 하지 않더라도 `AIMD`를 하기 전에 각 호스트들의 윈도우 크기대로 `hosts` 배열을 재정렬해주면 윈도우 크기의 평행 수렴은 구현되지만, 실제 네트워크에서는 이렇게 호스트들간의 AIMD 우선 순위를 관리하지 않고 각 호스트가 알아서 판단하는 구조이기 때문에 이 원리를 최대한 비슷하게 재현해보는 방향으로 작성하였다.

이제 필요한 클래스들의 작성이 끝났으니 한번 돌려보도록 하자.<small>(두근두근)</small>

```js
const network = new Network();
network.start();
const hostInterval = setInterval(() => {
  if (network.hosts.length > 9) {
    clearInterval(hostInterval);
  }
  const host = new Host(network.hosts.length);
  network.addHost(host);
}, 50);
```

10개의 호스트는 50ms에 한 개씩 네트워크에 추가될 것이며, 네트워크는 10ms마다 호스트들에게 AIMD 명령을 내린다. 이렇게 쭉 3초 동안 돌리고 나면 대략 이런 결과가 나온다.

```text
Phase 201 ==============
host0: 8.000000004656613
host1: 6.000000007450581
host2: 5.000000000931323
host3: 6.0000000055879354
host4: 8.00000000372529
host5: 9.00000000745058
host6: 10.000000014901161
host7: 5.000000014901161
host8: 6.000000029802322
host9: 7.000000059604645
host10: 8.00000011920929
```

200 페이즈 정도를 돌려보면 뒤늦게 네트워크에 합류했던 호스트들도 먼저 합류했던 호스트들에 비해 윈도우 크기가 크게 차이나지 않는 모습을 볼 수 있다. 물론 실제 네트워크와 동일한 환경은 아니지만, 실제 네트워크에서도 대략 이런 느낌으로 호스트들의 윈도우 크기가 어느 한쪽에 크게 몰리지 않고 평행 상태로 수렴하게 될 것이다.

이 코드를 직접 실행시켜서 중간 과정까지 모두 보고 싶으신 분들은 필자가 올려놓은 [깃허브 기스트](https://gist.github.com/evan-moon/77e56d2b763ba6b19004e591d1367267)에서 코드를 브라우저 콘솔에 복붙하거나 NodeJS로 실행시켜보길 바란다.

### Slow Start

### Congestion Avoidance

### Fast Recovery

### TCP Reno

### TCP Tahoe


